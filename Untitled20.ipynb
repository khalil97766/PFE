{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51f68d0-b9f7-47b8-99c9-30b5c41b4e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Part 1: Generating Data with APF Expert ---\n",
      "Running expert episode 1/50\n",
      "Running expert episode 2/50\n",
      "Running expert episode 3/50\n",
      "Running expert episode 4/50\n",
      "Running expert episode 5/50\n",
      "Running expert episode 6/50\n",
      "Running expert episode 7/50\n",
      "Running expert episode 8/50\n",
      "Running expert episode 9/50\n",
      "Running expert episode 10/50\n",
      "Running expert episode 11/50\n",
      "Running expert episode 12/50\n",
      "Running expert episode 13/50\n",
      "Running expert episode 14/50\n",
      "Running expert episode 15/50\n",
      "Running expert episode 16/50\n",
      "Running expert episode 17/50\n",
      "Running expert episode 18/50\n",
      "Running expert episode 19/50\n",
      "Running expert episode 20/50\n",
      "Running expert episode 21/50\n",
      "Running expert episode 22/50\n",
      "Running expert episode 23/50\n",
      "Running expert episode 24/50\n",
      "Running expert episode 25/50\n",
      "Running expert episode 26/50\n",
      "Running expert episode 27/50\n",
      "Running expert episode 28/50\n",
      "Running expert episode 29/50\n",
      "Running expert episode 30/50\n",
      "Running expert episode 31/50\n",
      "Running expert episode 32/50\n",
      "Running expert episode 33/50\n",
      "Running expert episode 34/50\n",
      "Running expert episode 35/50\n",
      "Running expert episode 36/50\n",
      "Running expert episode 37/50\n",
      "Running expert episode 38/50\n",
      "Running expert episode 39/50\n",
      "Running expert episode 40/50\n",
      "Running expert episode 41/50\n",
      "Running expert episode 42/50\n",
      "Running expert episode 43/50\n",
      "Running expert episode 44/50\n",
      "Running expert episode 45/50\n",
      "Running expert episode 46/50\n",
      "Running expert episode 47/50\n",
      "Running expert episode 48/50\n",
      "Running expert episode 49/50\n",
      "Running expert episode 50/50\n",
      "Generated 16741 training samples from successful expert episodes.\n",
      "\n",
      "--- Part 2: Pre-training the LSTM_FT model ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m18,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">53,569</span> (209.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m53,569\u001b[0m (209.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">53,569</span> (209.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m53,569\u001b[0m (209.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0951 - val_loss: 0.0265\n",
      "Epoch 2/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0257 - val_loss: 0.0083\n",
      "Epoch 3/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0099 - val_loss: 0.0067\n",
      "Epoch 4/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0078 - val_loss: 0.0038\n",
      "Epoch 5/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0064 - val_loss: 0.0041\n",
      "Epoch 6/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0067 - val_loss: 0.0033\n",
      "Epoch 7/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 8/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0056 - val_loss: 0.0030\n",
      "Epoch 9/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 10/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 11/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 12/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 13/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 14/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 15/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 16/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 17/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 18/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 19/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 20/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 0.0028\n",
      "\n",
      "--- Part 3: Fine-tuning to create LSTM_FTR model ---\n",
      "\n",
      "RL Epoch 1/10, Epsilon: 0.50\n",
      "Fine-tuning on 3036 samples from the best paths...\n",
      "\n",
      "RL Epoch 2/10, Epsilon: 0.45\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "# --- 1. Environment and Simulation ---\n",
    "\n",
    "# Constants\n",
    "GOAL_POS = (25.0, 25.0)\n",
    "ROBOT_SPEED = 1.0\n",
    "MAX_TURN_RATE = np.deg2rad(45)\n",
    "DT = 0.1\n",
    "MAX_EPISODE_STEPS = 500\n",
    "GOAL_RADIUS = 1.0\n",
    "SEQUENCE_LENGTH = 5 # How many past steps the LSTM should remember\n",
    "\n",
    "# Obstacles represented as rectangles [x_min, y_min, x_max, y_max]\n",
    "OBSTACLES = [\n",
    "    [10, 0, 12, 15],\n",
    "    [10, 20, 12, 30],\n",
    "    [18, 10, 20, 25]\n",
    "]\n",
    "\n",
    "class Robot:\n",
    "    def __init__(self, x, y, theta):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.theta = theta\n",
    "\n",
    "    def move(self, omega):\n",
    "        self.theta += np.clip(omega, -MAX_TURN_RATE, MAX_TURN_RATE) * DT\n",
    "        self.theta = math.atan2(math.sin(self.theta), math.cos(self.theta))\n",
    "        self.x += ROBOT_SPEED * math.cos(self.theta) * DT\n",
    "        self.y += ROBOT_SPEED * math.sin(self.theta) * DT\n",
    "        return (self.x, self.y), self.theta\n",
    "\n",
    "def get_lidar_readings(robot_pos, robot_theta, num_sensors=5, max_dist=10.0):\n",
    "    \"\"\"Simulates 5 Lidar sensors in a 180-degree arc.\"\"\"\n",
    "    readings = np.full(num_sensors, max_dist)\n",
    "    angles = np.linspace(-np.pi/2, np.pi/2, num_sensors) + robot_theta\n",
    "    \n",
    "    for i, angle in enumerate(angles):\n",
    "        for dist in np.arange(0.1, max_dist, 0.1):\n",
    "            px = robot_pos[0] + dist * math.cos(angle)\n",
    "            py = robot_pos[1] + dist * math.sin(angle)\n",
    "            for obs in OBSTACLES:\n",
    "                if obs[0] <= px <= obs[2] and obs[1] <= py <= obs[3]:\n",
    "                    readings[i] = dist\n",
    "                    break\n",
    "            if readings[i] != max_dist:\n",
    "                break\n",
    "    return readings\n",
    "\n",
    "def get_state(robot_pos, robot_theta):\n",
    "    \"\"\"Generates the 7-dimensional state vector for the neural network.\"\"\"\n",
    "    lidar = get_lidar_readings(robot_pos, robot_theta)\n",
    "    \n",
    "    dx = GOAL_POS[0] - robot_pos[0]\n",
    "    dy = GOAL_POS[1] - robot_pos[1]\n",
    "    \n",
    "    dist_to_goal = math.sqrt(dx**2 + dy**2)\n",
    "    angle_to_goal = math.atan2(dy, dx)\n",
    "    angle_diff = math.atan2(math.sin(angle_to_goal - robot_theta), math.cos(angle_to_goal - robot_theta))\n",
    "    \n",
    "    # State: [5 lidar readings, distance_to_goal, angle_to_goal]\n",
    "    # We normalize distances to be smaller values\n",
    "    state = np.concatenate((lidar / 10.0, [dist_to_goal / 30.0, angle_diff / np.pi]))\n",
    "    return state\n",
    "    \n",
    "# --- 2. The Expert and The Learner Models ---\n",
    "\n",
    "def apf_expert_policy(state):\n",
    "    \"\"\"A simple APF-based expert. It's good but can get stuck.\"\"\"\n",
    "    lidar_readings = state[:5] * 10.0\n",
    "    angle_to_goal = state[6] * np.pi\n",
    "    \n",
    "    # Repulsive force from obstacles\n",
    "    repulsive_omega = 0.0\n",
    "    # Give more weight to front sensors\n",
    "    weights = [0.1, 0.3, 1.0, 0.3, 0.1] \n",
    "    turn_directions = [np.pi/2, np.pi/4, 0, -np.pi/4, -np.pi/2]\n",
    "\n",
    "    for i in range(5):\n",
    "        if lidar_readings[i] < 3.0: # If an obstacle is close\n",
    "            # Force is inversely proportional to distance\n",
    "            repulsive_omega += weights[i] * (1.0 / max(lidar_readings[i], 0.1)) * turn_directions[i]\n",
    "\n",
    "    # Attractive force towards the goal\n",
    "    attractive_omega = 2.0 * angle_to_goal\n",
    "\n",
    "    # Combine forces\n",
    "    total_omega = attractive_omega - repulsive_omega # Subtract because repulsive turns away\n",
    "    return np.clip(total_omega, -MAX_TURN_RATE, MAX_TURN_RATE)\n",
    "\n",
    "def create_lstm_model(sequence_length, n_inputs, n_outputs):\n",
    "    model = Sequential([\n",
    "        Input(shape=(sequence_length, n_inputs)),\n",
    "        LSTM(64, return_sequences=True),\n",
    "        LSTM(64),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(n_outputs, activation='tanh') # Output is normalized turn rate [-1, 1]\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def run_episode(start_pos, start_theta, policy_model, use_exploration=False, epsilon=0.0):\n",
    "    \"\"\"Runs a single episode for any given model (expert or LSTM).\"\"\"\n",
    "    robot = Robot(x=start_pos[0], y=start_pos[1], theta=start_theta)\n",
    "    path_taken = [start_pos]\n",
    "    state_history = deque(maxlen=SEQUENCE_LENGTH)\n",
    "    \n",
    "    # Data for training\n",
    "    episode_sequences = []\n",
    "    episode_actions = []\n",
    "\n",
    "    for _ in range(MAX_EPISODE_STEPS):\n",
    "        pos = (robot.x, robot.y)\n",
    "        \n",
    "        # Get current state and update history\n",
    "        current_state = get_state(pos, robot.theta)\n",
    "        state_history.append(current_state)\n",
    "        \n",
    "        if len(state_history) < SEQUENCE_LENGTH:\n",
    "            # Not enough history, move straight-ish\n",
    "            omega = 0.1 * (random.random() - 0.5)\n",
    "        else:\n",
    "            sequence = np.array(state_history)\n",
    "            \n",
    "            if policy_model == \"expert\":\n",
    "                # Use the last state for the stateless expert\n",
    "                omega = apf_expert_policy(current_state)\n",
    "            else: # It's a Keras model\n",
    "                # Reshape for LSTM: (1, sequence_length, n_inputs)\n",
    "                nn_input = np.reshape(sequence, (1, SEQUENCE_LENGTH, 7))\n",
    "                # Model outputs a value in [-1, 1]\n",
    "                normalized_omega = policy_model.predict(nn_input, verbose=0)[0][0]\n",
    "\n",
    "                if use_exploration:\n",
    "                    if random.random() < epsilon:\n",
    "                        # Explore by adding random noise\n",
    "                        normalized_omega += random.uniform(-0.5, 0.5)\n",
    "                \n",
    "                # Scale it to the robot's max turn rate\n",
    "                omega = normalized_omega * MAX_TURN_RATE\n",
    "\n",
    "            # Store data for training\n",
    "            episode_sequences.append(sequence)\n",
    "            episode_actions.append(omega / MAX_TURN_RATE) # Store normalized action\n",
    "\n",
    "        new_pos, _ = robot.move(omega)\n",
    "        path_taken.append(new_pos)\n",
    "\n",
    "        # Check for success\n",
    "        if math.dist(new_pos, GOAL_POS) < GOAL_RADIUS:\n",
    "            return path_taken, True, episode_sequences, episode_actions\n",
    "\n",
    "    return path_taken, False, episode_sequences, episode_actions\n",
    "\n",
    "\n",
    "# --- 3. Main Execution Block ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # =========================================================================\n",
    "    # PART 1: Generate Training Data with the \"Expert\" (APF)\n",
    "    # =========================================================================\n",
    "    print(\"\\n--- Part 1: Generating Data with APF Expert ---\")\n",
    "    NUM_EXPERT_EPISODES = 50\n",
    "    all_expert_sequences = []\n",
    "    all_expert_actions = []\n",
    "\n",
    "    for i in range(NUM_EXPERT_EPISODES):\n",
    "        print(f\"Running expert episode {i+1}/{NUM_EXPERT_EPISODES}\")\n",
    "        start_pos = (random.uniform(0, 5), random.uniform(0, 5))\n",
    "        start_theta = random.uniform(-np.pi, np.pi)\n",
    "        _, success, sequences, actions = run_episode(start_pos, start_theta, \"expert\")\n",
    "        if success:\n",
    "            all_expert_sequences.extend(sequences)\n",
    "            all_expert_actions.extend(actions)\n",
    "\n",
    "    X_train_expert = np.array(all_expert_sequences)\n",
    "    y_train_expert = np.array(all_expert_actions)\n",
    "    print(f\"Generated {X_train_expert.shape[0]} training samples from successful expert episodes.\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # PART 2: Pre-train the LSTM model (Creating LSTM_FT)\n",
    "    # =========================================================================\n",
    "    print(\"\\n--- Part 2: Pre-training the LSTM_FT model ---\")\n",
    "    lstm_ft_model = create_lstm_model(SEQUENCE_LENGTH, 7, 1)\n",
    "    lstm_ft_model.fit(X_train_expert, y_train_expert, epochs=20, batch_size=32, validation_split=0.2)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PART 3: Fine-tune with Reinforcement Learning (Creating LSTM_FTR)\n",
    "    # =========================================================================\n",
    "    print(\"\\n--- Part 3: Fine-tuning to create LSTM_FTR model ---\")\n",
    "    # Make a copy to fine-tune, preserving the original FT model\n",
    "    lstm_ftr_model = tf.keras.models.clone_model(lstm_ft_model)\n",
    "    lstm_ftr_model.set_weights(lstm_ft_model.get_weights())\n",
    "    lstm_ftr_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    NUM_RL_EPOCHS = 10\n",
    "    EPISODES_PER_EPOCH = 20\n",
    "    epsilon = 0.5 # Initial exploration rate\n",
    "\n",
    "    for epoch in range(NUM_RL_EPOCHS):\n",
    "        print(f\"\\nRL Epoch {epoch+1}/{NUM_RL_EPOCHS}, Epsilon: {epsilon:.2f}\")\n",
    "        best_episodes_data = []\n",
    "        \n",
    "        for i in range(EPISODES_PER_EPOCH):\n",
    "            start_pos = (random.uniform(0, 5), random.uniform(0, 5))\n",
    "            start_theta = random.uniform(-np.pi, np.pi)\n",
    "            path, success, sequences, actions = run_episode(start_pos, start_theta, lstm_ftr_model, use_exploration=True, epsilon=epsilon)\n",
    "            \n",
    "            if success:\n",
    "                # Reward is inversely proportional to path length (shorter is better)\n",
    "                reward = 100 / len(path)\n",
    "                best_episodes_data.append({'reward': reward, 'sequences': sequences, 'actions': actions})\n",
    "\n",
    "        if not best_episodes_data:\n",
    "            print(\"No successful paths in this RL epoch, skipping training.\")\n",
    "            continue\n",
    "            \n",
    "        # Sort episodes by reward and take the top 50%\n",
    "        best_episodes_data.sort(key=lambda x: x['reward'], reverse=True)\n",
    "        top_episodes = best_episodes_data[:len(best_episodes_data)//2]\n",
    "        \n",
    "        # Collect data from only the best episodes for fine-tuning\n",
    "        X_fine_tune = []\n",
    "        y_fine_tune = []\n",
    "        for episode_data in top_episodes:\n",
    "            X_fine_tune.extend(episode_data['sequences'])\n",
    "            y_fine_tune.extend(episode_data['actions'])\n",
    "            \n",
    "        if X_fine_tune:\n",
    "            print(f\"Fine-tuning on {len(X_fine_tune)} samples from the best paths...\")\n",
    "            lstm_ftr_model.fit(np.array(X_fine_tune), np.array(y_fine_tune), epochs=5, batch_size=16, verbose=0)\n",
    "        \n",
    "        # Decrease exploration rate over time\n",
    "        epsilon = max(0.1, epsilon * 0.9)\n",
    "\n",
    "    # =========================================================================\n",
    "    # PART 4: Final Evaluation and Comparison\n",
    "    # =========================================================================\n",
    "    print(\"\\n--- Part 4: Evaluating all three models ---\")\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    \n",
    "    # Plot obstacles and goal\n",
    "    for obs in OBSTACLES:\n",
    "        plt.gca().add_patch(plt.Rectangle((obs[0], obs[1]), obs[2]-obs[0], obs[3]-obs[1], color='gray'))\n",
    "    plt.plot(GOAL_POS[0], GOAL_POS[1], 'r*', markersize=20, label='Goal')\n",
    "    \n",
    "    # Test all three models from the same starting point\n",
    "    eval_start_pos = (2, 2)\n",
    "    eval_start_theta = np.pi / 4\n",
    "\n",
    "    # 1. Expert Path\n",
    "    path_expert, _, _, _ = run_episode(eval_start_pos, eval_start_theta, \"expert\")\n",
    "    path_expert_np = np.array(path_expert)\n",
    "    plt.plot(path_expert_np[:, 0], path_expert_np[:, 1], 'b--', label=f'Expert (APF) Path - {len(path_expert)} steps')\n",
    "    \n",
    "    # 2. LSTM_FT Path\n",
    "    path_ft, _, _, _ = run_episode(eval_start_pos, eval_start_theta, lstm_ft_model)\n",
    "    path_ft_np = np.array(path_ft)\n",
    "    plt.plot(path_ft_np[:, 0], path_ft_np[:, 1], 'g-.', label=f'LSTM_FT Path - {len(path_ft)} steps')\n",
    "\n",
    "    # 3. LSTM_FTR Path\n",
    "    path_ftr, _, _, _ = run_episode(eval_start_pos, eval_start_theta, lstm_ftr_model)\n",
    "    path_ftr_np = np.array(path_ftr)\n",
    "    plt.plot(path_ftr_np[:, 0], path_ftr_np[:, 1], 'm-', linewidth=2.5, label=f'LSTM_FTR Path (Final) - {len(path_ftr)} steps')\n",
    "    \n",
    "    plt.title(\"Comparison of Expert, LSTM_FT, and LSTM_FTR Models\")\n",
    "    plt.xlabel(\"X Position\")\n",
    "    plt.ylabel(\"Y Position\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ec05b-c45a-4119-9bff-15e9242e959e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
